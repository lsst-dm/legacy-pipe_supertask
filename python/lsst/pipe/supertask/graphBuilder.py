#
# LSST Data Management System
# Copyright 2017 AURA/LSST.
#
# This product includes software developed by the
# LSST Project (http://www.lsst.org/).
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the LSST License Statement and
# the GNU General Public License along with this program.  If not,
# see <http://www.lsstcorp.org/LegalNotices/>.
#
"""
Module defining GraphBuilder class and related methods.
"""

from __future__ import print_function
from builtins import object

__all__ = ['GraphBuilder']

# -------------------------------
#  Imports of standard modules --
# -------------------------------
import copy
from collections import namedtuple

# -----------------------------
#  Imports for other modules --
# -----------------------------
from .expr_parser.parserYacc import ParserYacc, ParserYaccError
from .graph import QuantumGraphNodes, QuantumGraph
import lsst.log as lsstLog
from lsst.daf.butler import DatasetRef, Quantum

# ----------------------------------
#  Local non-exported definitions --
# ----------------------------------

_LOG = lsstLog.Log.getLogger(__name__)

# Tuple containing TaskDef, its input dataset types and output dataset types
#
# Attributes
# ----------
# taskDef : `TaskDef`
# inputs : `list` of `DatasetType`
# outputs : `list` of `DatasetType`
_TaskDatasetTypes = namedtuple("_TaskDatasetTypes", "taskDef inputs outputs")


class GraphBuilderError(Exception):
    """Base class for exceptions generated by graph builder.
    """
    pass


class UserExpressionError(GraphBuilderError):
    """Exception generated by graph builder for error in user expression.
    """

    def __init__(self, expr, exc):
        msg = "Failed to parse user expression `{}' ({})".format(expr, exc)
        GraphBuilderError.__init__(self, msg)


# ------------------------
#  Exported definitions --
# ------------------------


class GraphBuilder(object):
    """
    GraphBuilder class is responsible for building task execution graph from
    a Pipeline.

    Parameters
    ----------
    taskFactory : `TaskFactory`
        Factory object used to load/instantiate SuperTasks
    registry : :py:class:`daf.butler.Registry`
        Data butler instance.
    """

    def __init__(self, taskFactory, registry):
        self.taskFactory = taskFactory
        self.registry = registry

    @staticmethod
    def _parseUserQuery(userQuery):
        """Parse user query.

        Parameters
        ----------
        userQuery : `str`
            User expression string specifying data selecton.

        Returns
        -------
        `exprTree.Node` instance representing parsed expression tree.
        """
        parser = ParserYacc()
        # do parsing, this will raise exception
        try:
            tree = parser.parse(userQuery)
            _LOG.debug("parsed expression: %s", tree)
        except ParserYaccError as exc:
            raise UserExpressionError(userQuery, exc)
        return tree

    def _loadTaskClass(self, taskDef):
        """Make sure task class is loaded.

        Load task class, update task name to make sure it is fully-qualified,
        do not update original taskDef in a Pipeline though.

        Parameters
        ----------
        taskDef : `TaskDef`

        Returns
        -------
        `TaskDef` instance, may be the same as parameter if task class is
        already loaded.
        """
        if taskDef.taskClass is None:
            tClass, tName = self.taskFactory.loadTaskClass(taskDef.taskName)
            taskDef = copy.copy(taskDef)
            taskDef.taskClass = tClass
            taskDef.taskName = tName
        return taskDef

    def makeGraph(self, pipeline, collection, userQuery):
        """Create execution graph for a pipeline.

        Parameters
        ----------
        pipeline : :py:class:`Pipeline`
            Pipeline definition, task names/classes and their configs.
        collection : `str`
            Input collection name.
        userQuery : `str`
            String which defunes user-defined selection for registry, should be
            empty or `None` if there is no restrictions on data selection.

        Returns
        -------
        :py:class:`QuantumGraph` instance.

        Raises
        ------
        Exceptions will be raised on errors.
        """

        # make sure all task classes are loaded
        taskList = [self._loadTaskClass(taskDef) for taskDef in pipeline]

        # collect inputs/outputs from each task
        taskDatasets = []
        for taskDef in taskList:
            taskClass = taskDef.taskClass
            taskInputs = taskClass.getInputDatasetTypes(taskDef.config)
            taskInputs = list(taskInputs.values()) if taskInputs else []
            taskOutputs = taskClass.getOutputDatasetTypes(taskDef.config)
            taskOutputs = list(taskOutputs.values()) if taskOutputs else []
            taskDatasets.append(_TaskDatasetTypes(taskDef=taskDef,
                                                  inputs=taskInputs,
                                                  outputs=taskOutputs))

        # build initial dataset graph
        inputs, outputs = self._makeFullIODatasetTypes(taskDatasets)

        # make a graph
        return self._makeGraph(taskDatasets, inputs, outputs, collection, userQuery)

    def _makeFullIODatasetTypes(self, taskDatasets):
        """Returns full set of input and output dataset types for all tasks.

        Parameters
        ----------
        taskDatasets : sequence of `_TaskDatasetTypes`
            Tasks with their inputs and outputs.

        Returns
        -------
        inputs : `set` of `butler.DatasetType`
            Datasets used as inputs by the pipeline.
        outputs : `set` of `butler.DatasetType`
            Datasets produced by the pipeline.
        """
        # to build initial dataset graph we have to collect info about all
        # datasets to be used by this pipeline
        allDatasetTypes = {}
        inputs = set()
        outputs = set()
        for taskDs in taskDatasets:
            for dsType in taskDs.inputs:
                inputs.add(dsType.name)
                allDatasetTypes[dsType.name] = dsType
            for dsType in taskDs.outputs:
                outputs.add(dsType.name)
                allDatasetTypes[dsType.name] = dsType

        # remove outputs from inputs
        inputs -= outputs

        inputs = set(allDatasetTypes[name] for name in inputs)
        outputs = set(allDatasetTypes[name] for name in outputs)
        return (inputs, outputs)

    def _makeGraph(self, taskDatasets, inputs, outputs, collection, userQuery):
        """Make QuantumGraph instance.

        Parameters
        ----------
        taskDatasets : sequence of `_TaskDatasetTypes`
            Tasks with their inputs and outputs.
        inputs : `set` of `DatasetType`
            Datasets which should already exist in input repository
        outputs : `set` of `DatasetType`
            Datasets which will be created by tasks
        collection : `str`
            Input collection name.
        userQuery : `str`
            String which defunes user-defined selection for registry, should be
            empty or `None` if there is no restrictions on data selection.

        Returns
        -------
        `QuantumGraph` instance.
        """
        parsedQuery = self._parseUserQuery(userQuery or "")
        expr = None if parsedQuery is None else str(parsedQuery)
        header, rows = self.registry.selectDataUnits([collection], expr, inputs, outputs)
        _LOG.debug("header: %s", header)

        # store result locally for multi-pass algorithm below
        # TODO: change it to single pass
        unitVerse = []
        for row in rows:
            _LOG.debug("row: %s", row)
            unitVerse.append(row)

        def _unitColumns(units):
            """Returns indices of columns (in header) corresponding to a set of `units`"""
            return [col for col, (unit, link) in enumerate(header) if unit in units]

        # Next step is to group by task quantum units
        qgraph = QuantumGraph()
        for taskDss in taskDatasets:
            taskQuantaInputs = {}    # key is the quantum dataId (as tuple)
            taskQuantaOutputs = {}   # key is the quantum dataId (as tuple)
            qunits = taskDss.taskDef.config.quantum.units
            qcolumns = _unitColumns(qunits)
            _LOG.debug("qunits: %s -> %s", qunits, qcolumns)

            # some rows will be non-unique for subset of units, create
            # temporary structure to remove duplicates
            for row in unitVerse:
                qkey = tuple((header[col][1], row[col]) for col in qcolumns)
                _LOG.debug("qkey: %s", qkey)

                qinputs = taskQuantaInputs.setdefault(qkey, {})
                for dsType in taskDss.inputs:
                    dataIds = qinputs.setdefault(dsType, set())
                    ucolumns = _unitColumns(dsType.dataUnits)
                    dataId = tuple((header[col][1], row[col]) for col in ucolumns)
                    dataIds.add(dataId)
                    _LOG.debug("add input dataId: %s %s", dsType.name, dataId)

                qoutputs = taskQuantaOutputs.setdefault(qkey, {})
                for dsType in taskDss.outputs:
                    dataIds = qoutputs.setdefault(dsType, set())
                    ucolumns = _unitColumns(dsType.dataUnits)
                    dataId = tuple((header[col][1], row[col]) for col in ucolumns)
                    dataIds.add(dataId)
                    _LOG.debug("add output dataId: %s %s", dsType.name, dataId)

            # all nodes for this task
            quanta = []
            for qkey in taskQuantaInputs:
                # taskQuantaInputs and taskQuantaOutputs have the same keys
                _LOG.debug("make quantum for qkey: %s", qkey)
                quantum = Quantum(run=None, task=None)
                for dsType, dataIds in taskQuantaInputs[qkey].items():
                    for dataId in dataIds:
                        ref = DatasetRef(dsType, dict(dataId))
                        quantum.addPredictedInput(ref)
                        _LOG.debug("add input: %s", ref)
                for dsType, dataIds in taskQuantaOutputs[qkey].items():
                    for dataId in dataIds:
                        ref = DatasetRef(dsType, dict(dataId))
                        quantum.addOutput(ref)
                        _LOG.debug("add output: %s", ref)
                quanta.append(quantum)

            qgraph.append(QuantumGraphNodes(taskDss.taskDef, quanta))

        return qgraph
